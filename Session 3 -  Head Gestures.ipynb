{
 "metadata": {
  "name": "",
  "signature": "sha256:44f2ea2ae55e05b6e78c8b2fc30ce62b1fc9d9595f8981cae3d0191e5128d72e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Session 3: Head Gestures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This session deals with a specific non-verbal behaviour, namely head gestures\n",
      "\n",
      "The problem is a case study in temporal segmentations and multidimensional data, so it will offer a good opportunity to use materials from the previous two sessions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "NOTE: The following three cells need to be run to set up the environment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('X:\\\\2014_07_31_sk\\code\\python')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pylab as plt\n",
      "import pandas as pd  \n",
      "from mumodo.analysis import plot_scalar, create_intervalframe_from_streamframe, plot_annotations, intervalframe_overlaps\n",
      "from math import pi as PI\n",
      "from math import degrees"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.column_space',2000)\n",
      "pd.set_option('display.max_columns',40)\n",
      "pd.set_option('display.max_rows',400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Description of the problem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Human communication is characterized not only by speech, but also by behaviour that occur in other (so called) *modalities*. One of these modalities is the communicative function of head gestures. Without speaking, people can signal various meanings only by moving the head:\n",
      "\n",
      "* (dis-) agreement\n",
      "* (mis-) understanding\n",
      "* (un-) certainty\n",
      "* surprise\n",
      "\n",
      "The above (and much more) can be expressed using the so-called \"big four\" head gestures, namely NOD, SHAKE, TILT, JERK.\n",
      "\n",
      "It would be nice to have such data annotated in our corpora, but it is very time-consuming to annotate these manually"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 1: Load a video file (you will be instructed which one) into ELAN and annotate one-two head gestures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write down (in a text file) the steps you have to do to locate a head gesture, set its boundaries and obtain an annotation\n",
      "\n",
      "NOTE: Take one-two screenshots to create a short \"blog\" of the procedure (with text and images) as part of your portfolio"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 2: Export a textgrid from ELAN and upload it to studip"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the format: *firstname_lastname_session3.TextGrid*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Enter head tracking data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is of course much better to have automatically recorded motion capture data. But such data is high-dimensional, and we need to understand how it is represented\n",
      "\n",
      "First, let us import the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filepath = 'X:\\\\2014_07_31_sk\\sampledata\\session3\\s1.csv'\n",
      "frame = pd.DataFrame.from_csv(filepath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in frame.columns:\n",
      "    print col"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The head is a solid body, and as such its posture is defined on six (6) dimensions: \n",
      "\n",
      "* Three of these are the \"translation\", or more simply the *position* of the head in space (pos_X, pos_Y, pos_Z)\n",
      "* The other three are the \"orientation\", or more simply rotations of the head around its center"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(16,10))\n",
      "ax = fig.add_subplot(221)\n",
      "img=plt.imread('X:\\\\2014_07_31_sk\\sampledata\\session3\\images\\coordinatesystem.tiff')\n",
      "ax.imshow(img)\n",
      "ax = fig.add_subplot(222)\n",
      "img=plt.imread('X:\\\\2014_07_31_sk\\sampledata\\session3\\images\\yawpitchroll.jpg')\n",
      "ax.imshow(img)\n",
      "ax = fig.add_subplot(223)\n",
      "img=plt.imread('X:\\\\2014_07_31_sk\\sampledata\\session3\\images\\rotations1.tiff')\n",
      "ax.imshow(img)\n",
      "ax = fig.add_subplot(224)\n",
      "img=plt.imread('X:\\\\2014_07_31_sk\\sampledata\\session3\\images\\rotations2.tiff')\n",
      "ax.imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP3: Get a part of the data to analyze"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our data contains several sets of portrayed (deliberately performed) head gestures\n",
      "\n",
      "We can see these section of the data as follows "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = set(frame['speakerID'])\n",
      "labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This means that speaker1 performed five sets of each of the basic four gestures. Take just one label out of the main frame:\n",
      "\n",
      "NOTE: You will be instructed as which slice of the data to analyse "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label = 's1jerk1'\n",
      "subframe = frame[frame['speakerID'] == label]\n",
      "subframe.index = subframe.time\n",
      "subframe['rot_pitch'] = subframe['rot_pitch'].map(lambda x: round(x,6) - PI if x>0 else x + PI)\n",
      "subframe.ix[:500]  #the fisrt half second of this data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 4: Create an intervalframe of the labels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the \"label\" column (far right) shows the manually annotated boundaries of the gestures. Create an intervalframe in which the label is not equal to \"None\". Immediately turn the time units to seconds\n",
      "\n",
      "HINT: remove the semi-colon on the last line to see the intervals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervalframe1 = create_intervalframe_from_streamframe(subframe,'label', lambda x: x != \"None\", 100, text=label)\n",
      "intervalframe1['start_time'] /= 1000.\n",
      "intervalframe1['end_time'] /= 1000.\n",
      "intervalframe1;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 5: Plot the intervalframe "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HINT: You have done this before. Look at the old notebooks for an example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 6: Plot the three rotation axis together in one plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HINT: Again, look at the old notebooks for an example\n",
      "\n",
      "* You can set the range (in milliseconds) in order to \"zoom in\" a smaller time region\n",
      "* You can use the *filepath* keyword argument to save the plot to a file (for your portfolio). NOTE: The file *must* have a\n",
      "valid extension, such as .png or .jpg\n",
      "* The units of the rotation angels are *radians*. Can you covert them to degrees (using the degrees() function) ?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observations on plot\n",
      "\n",
      "Can you identify which of the three rotation axes is associated with your gestures?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 7: Create an intervalframe using a threshold of rotation on your identified axis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HINT: You have done this again, check the old notebooks. There is even an example in *this* notebook\n",
      "\n",
      "The goal is to find a threshold value in order to *segment* the streamframe to intervals in which the rotation is *higher* \n",
      "than that threshold\n",
      "\n",
      "* Use a new variable name to store the new object, e.g. intervalframe2 = ...\n",
      "* Again, immediately turn the time from milliseconds to seconds\n",
      "* Print your new intervalframe as a table\n",
      "* plot yout intervalframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 8: Find the *overlaps* between the two intervalframes (manual and automatic)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HINT: Again, look at the old notebooks for an example\n",
      "\n",
      "Plot the two intervalframes and the overlaps together in *one* plot. What do you observe?\n",
      "\n",
      "HINT: You may get an error in case of zero overlap. Check if your \"overlaps\" intervalframe is empty. Try plotting only the other two in such case"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 9: Save the 3-textgrids plot to a file (jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Again, use the *filepath=* argument of the plotting function you used\n",
      "* You can include this plot in your portfolio\n",
      "* When uploading, use the file format: *firstname_lastname_plot.jpg\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}