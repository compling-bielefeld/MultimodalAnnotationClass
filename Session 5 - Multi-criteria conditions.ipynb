{
 "metadata": {
  "name": "",
  "signature": "sha256:8f771d23bb9e53ddc0f27f9a75dd9b95019250ec2270b4b27b02b109fcf879c0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Session 5: Multi-criteria conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This session deals with combining multimodal data to extract properties of the dialogue\n",
      "\n",
      "Often we have available annotations (series of intervals) about different properties of the dialogue and we wish to \n",
      "combine that information and arrive at new conclusions\n",
      "\n",
      "We can easily perform this by evaluating *conditions* by checking for the presence/absence of intervals of specific tiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('X:\\\\2014_07_31_sk\\code\\python')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pylab as plt\n",
      "import pandas as pd  \n",
      "from mumodo.mumodoIO import open_intervalframe_from_textgrid, save_intervalframe_to_textgrid\n",
      "from mumodo.analysis import plot_annotations, intervalframe_overlaps, intervalframe_union"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.column_space',2000)\n",
      "pd.set_option('display.max_columns',40)\n",
      "pd.set_option('display.max_rows',400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 1: Import data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You will be instructed as to the specific data files to import\n",
      "\n",
      "The data comes from a dialogue (speakers A and B) and will consist of two textgrids\n",
      "\n",
      "* transcriptions\n",
      "* head gestures "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename1 = 'X:\\\\2014_07_31_sk\\sampledata\\session5\\somefile'\n",
      "filename2 = 'X:\\\\2014_07_31_sk\\sampledata\\session5\\otherfile'\n",
      "transcription = open_intervalframe_from_textgrid(filename1)\n",
      "headgestures = open_intervalframe_from_textgrid(filename2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 2: See & plot the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "REMINDER: the objects stored in the variables *transcripion* and *head gestures* are Python *dictionaries*\n",
      "\n",
      "In order to see the *keys* you simply write:\n",
      "\n",
      "    mydict.keys()\n",
      "    \n",
      "To get the *value* of a key:\n",
      "\n",
      "    mydict[key]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transcription.keys()\n",
      "headgestures.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "REMINDER: The *values* of this dictionary are *intervalframes*, i.e. tables of intervals\n",
      "\n",
      "You can see a table simply by doing:\n",
      "    \n",
      "    transcriptions[key];\n",
      "\n",
      "* *key* has to be a valid key.\n",
      "* remove the semicolon to actually see the table, then put it back to hide it, as it is very long "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to make a new dictionary so that we can plot everything together\n",
      "\n",
      "Dictionaries are enclosed in \"curly brackets\" and have the following syntax:\n",
      "\n",
      "    {key1: value1, key2: value2, ...}\n",
      "    \n",
      "Keys are typically strings (i.e. names), and we can select any names we like, as we do below\n",
      "\n",
      "Duplicate names *overwrite* the value (which the thing after the colon)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotdict = {'A': transcription['A'], \n",
      "            'B': transcription['B'],\n",
      "            'headA': headgestures['headA'],\n",
      "            'headB': headgestures['headB']}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally make the plot, using the imported function plot_annotations\n",
      "\n",
      "The textgrids are too long to be plotted whole within the page, which means you can either: \n",
      "\n",
      "* plot a part of the textgrid, from time1 to time2\n",
      "* set the *scalefactor* to something low \n",
      "\n",
      "You can set the *order* in which the tiers are plotted\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_annotations(plotdict, scalefactor=0.1,  tierorder=['A', 'headA', 'B', 'headB'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "TURN TAKING"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In dialogue speech research, a lot of work is directed towards turn-taking, i.e. the exchange of turns between interlocutors in a dialogue. Our first task is to find intervals of interest to the study of turn-taking.\n",
      "\n",
      "As shown in the figure below, these are 4 types of intervals:\n",
      "\n",
      "* speaker A\n",
      "* speaker B\n",
      "* overlap \n",
      "* silence"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(10,6))\n",
      "ax = fig.add_subplot(111)\n",
      "img=plt.imread('X:\\\\2014_07_31_sk\\sampledata\\session5\\images\\timeline_cropped.png')\n",
      "ax.imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 3: Find the intervals of interest"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to find the intervals where:\n",
      "\n",
      "* both speakers speak\n",
      "* any of the speakers speaks\n",
      "\n",
      "We have two functions that do exactly this (look at the top of the notebook, second cell, where we import them)\n",
      "\n",
      "Store the new tiers that are created into variables with meaningful names, e.g.\n",
      "\n",
      "    speechoverlaps = intervalframe_overlaps(transcription['A'], transcription['B'])"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 4: Plot the intervals of interest"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the following intervals together in this order:\n",
      "\n",
      "* speechA\n",
      "* speechB\n",
      "* overlaps\n",
      "* anyspeech\n",
      "\n",
      "You should use the dictionary we used for plotting before\n",
      "\n",
      "REMINDER: You can always add a new key to a dictionary like so:\n",
      "\n",
      "    mydict[newkey] = value\n",
      "    \n",
      "CAREFUL not to use a key that already exist, that would overwrite the previous value"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add keys to the dict here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot the tiers here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 5: Save the plotting dictionary as a textgrid on disk"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the file on Desktop, using the function below:\n",
      "\n",
      "    save_intervalframe_to_textgrid()\n",
      "\n",
      "Name the file using your full name, e.g.\n",
      "\n",
      "spyroskousidis.TextGrid\n",
      "\n",
      "UPLOAD the file to studIP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "INTERMISSION"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What did we just do?\n",
      "\n",
      "We combined information about *when* A or B is speaking to arrive at new information (both speaking or anyone speaking).\n",
      "\n",
      "The above constitutes a multi-condition: we want something to be true, while something else is also true. We saw two types:\n",
      "\n",
      "* overlaps: This is an AND operation, also known as intersection of two sets. We want both conditions to be true (A is speaking and B is speaking)\n",
      "\n",
      "* allspeech: This is an OR operarion, also known as union of two sets. We want either condition to be true (either A or B or both are speaking)\n",
      "\n",
      "We can further expand two more than two conditions, making chains of co-called *boolean* operations (e.g. AND, OR). \n",
      "\n",
      "Thinking about combining information in this way makes it simple and intuitive to perform multimodal analysis, as will be shown\n",
      "below"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "HEAD GESTURES AND SPEECH"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We turn our attention now to the modality of head gestures\n",
      "\n",
      "We would like to know the distribution of head gestures with relation to the turns, in other words if people gesture more with their heads when they have the turn than when they don't."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 6: Find out and plot the head gestures of speaker A while speaker A *speaks*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, we want two conditions to be true: \n",
      "\n",
      "* speaker A speaks\n",
      "* speaker A is performing a head gesture\n",
      "\n",
      "Since we want both conditions to be true, we use an AND operation, between two tiers:\n",
      "\n",
      "* transcription['A']: these are the speech intervals of speaker A\n",
      "* headgestures['headA']: these are the head gestures of speaker A\n",
      "\n",
      "We find an informative variable name to store the new object, e.g:\n",
      "\n",
      "speakergesturesA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "speakergesturesA = intervalframe_overlaps(transcription['A'], headgestures['headA'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to plot, we need to create (or add to) our plotting dictionary\n",
      "\n",
      "We can see the keys that are already there, using:\n",
      "\n",
      "    plotdict.keys()\n",
      "\n",
      "And add a new key/value using:\n",
      "\n",
      "    plotdict['new key'] = value\n",
      "    \n",
      "HINT: You don't have to plot all the keys that are in the plot dictionary. Using the *tier_order* argument, you can select the\n",
      "subset that is plotted. Here we plot the speech of speaker A, the overlaps of speaker A and the overlap between the two"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plotdict['sgA'] = speakergesturesA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_annotations(plotdict, scalefactor=0.1, tierorder=['A', 'headA', 'sgA']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 7: Compare the two amounts of gestures "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have two sets of gestures (all gestures of speaker A and all \"speaker gestures\" of speaker A, we would like to know\n",
      "the percentage of gestures that are \"speaker gestures\" \n",
      "\n",
      "NOTE: This is actually a valid research question\n",
      "\n",
      "Below we define a function that gets the number and total duration of intervals in an intervalframe (table)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getnumberandduration(intervalframe):\n",
      "    return len(intervalframe), (intervalframe['end_time'] - intervalframe['start_time']).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the function above as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getnumberandduration(headgestures['headA'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or we can store the results in variables (note that the function returns two values, so we need two variables)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headA_count, head_duration = getnumberandduration(headgestures['headA'])\n",
      "sgA_count, sgA_duration = getnumberandduration(speakergesturesA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can get the percentage in number and duration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(100 * headA_count) / float(sgA_count), 100 * head_duration / sga_duration"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We notice that the count is misleading, and we can see that in our plot above (step 6): Due to the way the overlap function works, the actual *number* (count) of overlapping intervals can actually be more than the original intervals. \n",
      "\n",
      "The duration percentage however, should give a good indication of the percentage of gestures in different conditions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 8: Calculate more percentages "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the procedure above, calculate the following percentages (NOTE: this is real research now)\n",
      "\n",
      "* speaker gestures of speaker A over all gestures of speaker A (you did this just now directly above)\n",
      "* listener gestures of speaker A over all gestures of speaker A (listener gestures are gestures performed by A while *B* is speaking\n",
      "* overlap gestures of speaker A over all gestures of speaker A (gestures of speaker A while simultanous speech occurs)\n",
      "* anyspeech gestures of speaker A over all gestures of speaker A (gestures of speaker A while either speaker A or B speak)\n",
      "* The above four measures for speaker B\n",
      "\n",
      "HINT: name the variables for the intervalframes you create *meaningfully*, e.g. *allspeechgesturesA*\n",
      "\n",
      "HINT: You can copy paste the two previous code cells to calculate the percentage (duration only):\n",
      "\n",
      "    head_duration = getnumberandduration(headgestures['headA'])\n",
      "    sgA_duration = getnumberandduration(speakergesturesA)\n",
      "    \n",
      "    perecentage = round(100 * head_duration / sga_duration,1)\n",
      "    \n",
      "NOTE: You should always add the new intervalframes you create to the plotting dictionary and plot the ones you need using the *tier_order* argument \n",
      "\n",
      "You can find out other interesting conditions, too, e.g.:\n",
      "\n",
      "* Simultaneous gestures (speaker A and speaker B are both gesturing)\n",
      "* Simultaneous gestures AND simultaneous speech\n",
      "\n",
      "Or you can think of your own research questions, too!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OPTIONAL CODING TASK"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If interested in coding in Python, here is a nice exercise:\n",
      "\n",
      "The following lines calculate the percentage (duration):\n",
      "\n",
      "    head_duration = getnumberandduration(headgestures['headA'])\n",
      "    sgA_duration = getnumberandduration(speakergesturesA)\n",
      "\n",
      "    100 * head_duration / sga_duration\n",
      "    \n",
      "Can you make a function to automatically compute duration percentages of intervalframes? It would be called so:\n",
      "\n",
      "    get_duration_percentage(intervalframe1, intervalsframe2) \n",
      "    \n",
      "and would return a signel number\n",
      "\n",
      "HINT: Functions in Python are defined so: \n",
      "\n",
      "    def myfunctionname(argument1, argument2, ....):     #<--- Note you need a colon there\n",
      "        #something is happening here\n",
      "        return returnvalue       # <-- You need a return statement for your function to return something"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}