{
 "metadata": {
  "name": "",
  "signature": "sha256:017f1e8bd6c2654656fb1352c9165ad668d15f4c322cf470cdaa2e366bcdfa76"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Session 2: Multi-dimensional data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This session introduces the concept of working with data with higher dimensions. In particular, we look at how it is possible to do the following:\n",
      "\n",
      "* visualize\n",
      "* manipulate (e.g. sort, deal with outliers, etc)\n",
      "* query \n",
      "* analyze and extract information\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "NOTE: The following cells need to be run to set up the environment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('X:\\\\2014_07_31_sk\\code\\python')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pylab as plt\n",
      "import pandas as pd  \n",
      "from mumodo.mumodoIO import open_streamframe_from_xiofile, save_intervalframe_to_textgrid, XIOFile\n",
      "from mumodo.analysis import plot_scalar, plot_vector, create_intervalframe_from_streamframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.column_space',2000)\n",
      "pd.set_option('display.max_columns',40)\n",
      "pd.set_option('display.max_rows',400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 1: Import motion capture data from Kinect Sensor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filepath = 'X:\\\\2014_07_31_sk\\\\sampledata\\\\r1_12_15.xio.gz'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "WARNING: The following cell will take long to execute!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kinect = open_streamframe_from_xiofile(filepath, 'lab-labtop/irioKinect')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 2: Query the object to see what data labels it contains"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in kinect.columns:\n",
      "    print col"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of the columns above refer to the joints of a skeleton model as exported by the Kinect sensor\n",
      "\n",
      "What type of data describes the positions of each joint?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 3: Get one datapoint"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapoint = kinect.AnkleLeft.iloc[0]\n",
      "datapoint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above tells as that the datapoint is an SFVec3f, in other words, a vector of three floating point numbers, a 3D coordinate!\n",
      "\n",
      "NOTE: The units are meters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print datapoint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to look at the x,y, or z coordinate of a datapoint individualy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapoint.x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 4: Get a slice of the data, representing only the upper body"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a slice of the data, you need a subset of the columns. You can do this with the following syntax:\n",
      "\n",
      "    newobject = kinect.ix[:,['ElbowLeft', 'ElbowRight']]\n",
      "    \n",
      "Name your newobject \"upperbody\". \n",
      "\n",
      "NOTE: You have to write the proper command in the following cell to complete this step"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody = kinect.ix[:,['ElbowLeft', 'ElbowRight','HandLeft', 'HandRight', 'Head', 'ShoulderCenter',\n",
      "                             'ShoulderLeft', 'ShoulderRight','WristLeft', 'WristRight']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Verify that you have sliced all the columns you want"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in upperbody.columns:\n",
      "    print col"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the data\n",
      "\n",
      "NOTE: The whole data table does not fit in the notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#remove the semi column to display the data\n",
      "upperbody;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why is the \"time\" a big big number? \n",
      "\n",
      "The short answer is that this is a format all computers understand. In order to make it meaningfulf for us, we simply subtract the first number from all the numbers, making the first time zero"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "upperbody.index -= upperbody.index[0]\n",
      "upperbody.sort_index(inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the data again (by running the cell before the previous one)\n",
      "\n",
      "It is clearer now, that the data comes in frames every 10 milliseconds or so "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The whole time range is equal to"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody.index[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or approximately 180 sec or 3 minutes!\n",
      "\n",
      "It is possible to look at a specific time slice, using the following syntax:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody.ix[70000:71000]  #this is 1 second"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 5: Visualize the whole upper body at time"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since we might want to be doing this for multiple times, it is good to define a *function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_upperbody(frame_time):\n",
      "    upperbody2 = upperbody.ix[:,['HandLeft', 'WristLeft', 'ElbowLeft', 'ShoulderLeft', 'ShoulderCenter',\n",
      "                            'ShoulderRight', 'ElbowRight','WristRight','HandRight']]\n",
      "    fig = plt.figure(figsize=(8,8))\n",
      "    ax = fig.add_subplot(111, projection='3d')\n",
      "    xs ,ys, zs = [], [], []\n",
      "    for joint in upperbody2.columns:\n",
      "        xs.append(upperbody[joint].ix[frame_time].x)\n",
      "        ys.append(upperbody[joint].ix[frame_time].y)\n",
      "        zs.append(upperbody[joint].ix[frame_time].z)\n",
      "    ax.scatter(xs, ys, zs, s=150,c='b')\n",
      "    ax.scatter(upperbody['Head'].ix[frame_time].x, upperbody['Head'].ix[frame_time].y, upperbody['Head'].ix[frame_time].z, s = 300)\n",
      "    ax.plot(xs,ys,zs)\n",
      "    \n",
      "    ax.set_xlabel('X')\n",
      "    ax.set_ylabel('Y')\n",
      "    ax.set_zlabel('Z');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now plot the upper body at a time representing a frame of data\n",
      "\n",
      "Try different data points (times)\n",
      "\n",
      "NOTE: the time *must* exist in the data table"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_upperbody(70001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 6: Plot data over time"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With one dimensional data, it is usual to plot against time, e.g.\n",
      "\n",
      "Can you plot 'headY' and 'headZ' ?\n",
      "\n",
      "NOTE: You need to edit the lambda function that extract one coordinate from the vector \"in-place\" \n",
      "\n",
      "NOTE: You need to drop the NaN before attempting to extract one coordinate, because NaN is not a vector, it is just NaN\n",
      "\n",
      "NOTE: You can specify a time range (in milliseconds)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody['headX'] = upperbody['Head'].dropna().map(lambda x: x.x) #we define a column of 1-D data\n",
      "plot_scalar(upperbody, ['headX'], 0 ,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How can we plot multidimensional data over time? \n",
      "\n",
      "One solution is to plot it in 2D data in 3D with 3rd axis as time, but that is confusing. \n",
      "\n",
      "Another way is to apply a *color code* to time, e.g.\n",
      "\n",
      "Try different colormaps, by changing the last argument of the plot_vector() function. \n",
      "\n",
      "HINT: Hit the TAB key aftet placing the cursor directly after \"plt.cm.\": A list of possible colormaps will appear\n",
      "\n",
      "NOTE: You can try different time limits as well!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody.dropna(inplace=True)\n",
      "plot_vector(upperbody, 'Head', 15000, 22000, colormap = plt.cm.jet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 7: Find interesting regions of hand movement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to know whether the subjects are doing any interesting gestures with their hands. Finding that manually would require to watch the whole video. Instead, we will use the motion capture data that we have!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to find out whether there are any hand gestures, we consider whether the hands are *higher* than their rest position. \n",
      "\n",
      "HINT: The up-down axis is axis Y\n",
      "\n",
      "Therefore, we need to plot the Y coordinate of each hand (for the whole interval) \n",
      "\n",
      "NOTE: You have to edit the following cell to plot the Y coordinate of the hand\n",
      "\n",
      "HINT: Plot both hands. It is possible to plot both at the same time!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upperbody['HandLeftY'] = upperbody['HandLeft'].dropna().map(lambda x: x.y) #we define a column of 1-D data\n",
      "upperbody['HandRightY'] = upperbody['HandRight'].dropna().map(lambda x: x.y) #we define a column of 1-D data\n",
      "plot_scalar(upperbody, ['HandLeftY', 'HandRightY'], 0 ,0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We notice that there are some regions in which either one or both hands are positioned up to 0.5 meters higher than usual, probably pointing at something! We would like to see that!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 8: Output a textgrid with the areas of interest"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like, of course, to have a series of \"intervals of interest\" to show in ELAN together with the video\n",
      "\n",
      "If you recall from the introduction session, we could do this by creating intervals from a time series based on a threshold. If hand is higher than a value x, then we want this marked:\n",
      "\n",
      "NOTE: Adjust the threshold to something sensible and rerun the cell several times until you are happy with the result\n",
      "\n",
      "HINT: You can 'zoom in\" a time range to see specific sub-intervals "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = -0.4\n",
      "upperbody['threshold'] = upperbody['HandLeftY'].map(lambda x: threshold)\n",
      "intervalsleft = create_intervalframe_from_streamframe(upperbody, 'HandLeftY', lambda x: True if x>threshold else False, 500)\n",
      "plot_scalar(upperbody, ['threshold', 'HandLeftY'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the detected intervals\n",
      "\n",
      "HINT: Turn the seconds into milliseconds, and change the label to reflect the threshold you used\n",
      "\n",
      "HINT: The following cell can be run only once. If you change the threshold above, rerun both cells"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervalsleft['start_time'] /= 1000. \n",
      "intervalsleft['end_time'] /= 1000. \n",
      "intervalsleft['text'] = intervalsleft['text'].map(lambda x: \" > \" + str(threshold))\n",
      "intervalsleft                                   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the cell below, do the same for the second hand!\n",
      "\n",
      "NOTE: You may need to adjust a different threshold!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = -0.4\n",
      "upperbody['threshold'] = upperbody['HandRightY'].map(lambda x: threshold)\n",
      "intervalsright = create_intervalframe_from_streamframe(upperbody, 'HandRightY', lambda x: True if x>threshold else False, 500)\n",
      "plot_scalar(upperbody, ['threshold', 'HandRightY'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervalsright['start_time'] /= 1000. \n",
      "intervalsright['end_time'] /= 1000. \n",
      "intervalsright['text'] = intervalsright['text'].map(lambda x: \" > \" + str(threshold))\n",
      "intervalsright                                   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now save your data to a Textgrid file!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "save_intervalframe_to_textgrid({'A-left-hand': intervalsleft, 'A-right-hand': intervalsright}, \"testgridA.TextGrid\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 9: Repeat previous step for the *second* speaker"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HINT: You need to re-import a different motion capture data set, with:\\\n",
      "\n",
      "    kinect = open_streamframe_from_xiofile(filepath, 'lab-labtop/irioKinect 2')\n",
      "      \n",
      "HINT: You need to re-define upperbody, take care of NaN same as the first time around, etc (just copy-paste some cells)\n",
      "\n",
      "HINT: You can save all four tiers (two hands per speaker) in *one* textgrid, e.g.\n",
      "\n",
      "    save_intervalframe_to_textgrid({'A-left-hand': intervalsleftA, \n",
      "                                    'A-right-hand': intervalsrightA,\n",
      "                                    'B-left-hand': intervalsleftB, \n",
      "                                    'B-right-hand': intervalsrightB}, \"testgridA.TextGrid\")\n",
      "                         \n",
      "HINT: You can insert more cells as you need, using the insert menu at the top of the screen"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 10: Upload you textgrid(s) to STUDIP "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the following naming format: \n",
      "\n",
      "    firstnamelastnameSession2.Textgrid\n",
      "\n",
      "If you have more than one (e.g. one per speaker A, B):\n",
      "\n",
      "    firstnamelastnameSession2A.Textgrid"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 11: Import TextGrid into ELAN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Open the respective video file and import your textgrid into ELAN. Can you assign labels A and B to the two speakers? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download and import textgrids from your classmates (who potentially have used different thresholds"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}