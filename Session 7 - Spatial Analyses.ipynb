{
 "metadata": {
  "name": "",
  "signature": "sha256:e1c3c62a38ac855e577505db62dfe71e270f3fffcc51755937d28c17fa7460a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Session 7 - Spatial Analyses"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have so far mainly look into temporal analysis, i.e. *when* things happen \n",
      "\n",
      "It is now time to turn towards spatial properties of the data, i.e. *where* things happen\n",
      "\n",
      "This is an introductory session in this direction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('X:\\\\2014_07_31_sk\\code\\python')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pylab as plt\n",
      "import pandas as pd  \n",
      "from mumodo.mumodoIO import open_intervalframe_from_textgrid, open_streamframe_from_xiofile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.column_space',2000)\n",
      "pd.set_option('display.max_columns',40)\n",
      "pd.set_option('display.max_rows',600)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 1: Import data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We import three types of data:\n",
      "\n",
      "* The Pentomino pieces location\n",
      "* The gaze tracking points\n",
      "* The trascriptions & episode boundaries (exported from ELAN)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename1 = 'X:\\\\2014_07_31_sk\\\\sampledata\\\\session7\\\\r6_distribute_data.xio.gz'\n",
      "boards = open_streamframe_fro  m_xiofile('filename1', 'xioFileClass/pento')\n",
      "gaze = open_streamframe_from_xiofile('filename1', 'xioFileClass/gaze')\n",
      "infos = open_intervalframe_from_textgrid('Desktop/r6_infos.TextGrid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 2: Process Pento Board Information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boards.columns\n",
      "boards;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the pentomino objects are coded in a string of the following form:\n",
      "\n",
      "tile-9(grid3,N,gray,0,2,0,false,false,399.0,684)\n",
      "\n",
      "Although this contains all the information we need, we would like a more usable representation. Therefore, we define a new type of object, called tile, with the following properties:\n",
      "\n",
      "* shape\n",
      "* color\n",
      "* is_selected\n",
      "* x coordinate (screen pixel)\n",
      "* y coordinate (screen pixel)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class tile(object):\n",
      "    \"a simple class that parses board objects strings\"\n",
      "    def __init__(self, objectstring):\n",
      "        tokens = objectstring.split(\",\")\n",
      "        self.shape = tokens[1]\n",
      "        self.color = tokens[2]\n",
      "        self.is_selected = tokens[7] == 'true'\n",
      "        self.x = int(float(tokens[8]))\n",
      "        self.y = int(tokens[9][:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We test our new object type, printing the properties of our tile!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "atile = tile(boards['object1'].ix[499809])\n",
      "atile.color, atile.is_selected, atile.shape, atile.x, atile.y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It makes sense then to convert all data in the boards table into such objects, as they are much more usable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del boards['time']\n",
      "for c in boards.columns:\n",
      "    boards[c] = boards[c].map(lambda x: tile(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 3: Process Gaze tracking information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gaze;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the gaze points are coded as pairs of coordinates (pixels) on screen"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "point = gaze['pixels'].ix[220300]\n",
      "point"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we see, the point is also an object type (SFVec2f), a vector of two floating point numbers\n",
      "\n",
      "We can get each coordinates as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "point.x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "point.y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gaze)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that our gaze table is rather large and contains some entries with value (-1000, -1000)\n",
      "\n",
      "To get rid of this value, we use the well known to us method of subsetting/slicing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gazegood = gaze[gaze['pixels'].map(lambda x: x.x) != -1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gazegood)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 4: Process annotation data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infos.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infos['episodes'];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nothing to do really, just note that the times of the textgrids are in *seconds*, while all other times in the other tables (gaze, boards) are in *millisecons*, which means we will have to multiply by 1000 if we want to combine these tables somehow later:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in infos.keys():\n",
      "    infos[key]['start_time'] *= 1000\n",
      "    infos[key]['end_time'] *=1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infos;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 5: Plot a board of pieces together with gaze"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define a plotting function that can show the following:\n",
      "\n",
      "* a list of tile objects\n",
      "* all gaze points during a specific time range, i.e. a *slice* of the gaze points table"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_screen(tiles, gazepoints, filepath=None):\n",
      "    \"\"\" plot an episode screen\n",
      "    \n",
      "    tiles -- a list of tile objects\n",
      "    gaze points -- a series of sfvec2f objects\n",
      "    \n",
      "    filepath -- optional argument to save the plot to\n",
      "                a file. The filepath MUST be have a \n",
      "                valid image extension, e.g. \"file.png\"\n",
      "                (bmp, jpg, etc)\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "    #read gaze points\n",
      "    gazeX = gazepoints['pixels'].map(lambda x: x.x)\n",
      "    gazeY = gazepoints['pixels'].map(lambda x: x.y)\n",
      "    gazeI = gazepoints.index\n",
      "    \n",
      "    \n",
      "    #create figure\n",
      "    fig = plt.figure(figsize=(16,9))\n",
      "    ax = fig.add_subplot(111)\n",
      "    \n",
      "    ax.set_xlim(-200,2120)\n",
      "    ax.set_ylim(-200,1280)\n",
      "    ax.set_ylim(ax.get_ylim()[::-1])\n",
      "    ax.add_patch(plt.Rectangle((0,0),1920,1080,alpha = 0.05,color = 'b'))\n",
      "    gax = ax.scatter(gazeX, gazeY, s= 10, c = gazeI, cmap = plt.cm.Reds, label = 'gaze')\n",
      "    fig.colorbar(gax, format = '%d')\n",
      "    \n",
      "    #draw the objects\n",
      "    for tile in tiles:\n",
      "        if tile.is_selected:\n",
      "            ax.text(tile.x, tile.y, tile.shape, size = 'xx-large', weight = 'bold', \n",
      "                        color = tile.color, bbox=dict(facecolor='red', alpha=0.5))   \n",
      "        else:\n",
      "            ax.text(tile.x, tile.y, tile.shape, size = 'xx-large', weight = 'bold', color = tile.color)\n",
      "    if filepath is not None:\n",
      "        fig.savefig(filepath, format=filepath.split('.')[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to obtain a list of tiles, we simply call a row of the boards table\n",
      "\n",
      "(we do not *see* any values while doing this, rather we validate that there are only *tile* objects in our list)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boards.ix[804261]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We already know how to slice the gaze information table around a time range (from our session 2 notebook!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gazegood.ix[760000:800000];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So the above two objects (list of tiles and slice of gaze points are the arguments to our function)\n",
      "\n",
      "We can now see the plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_screen(boards.ix[804261], gazegood.ix[760000:800000])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The shaded area represents the screen, while objects are represented as letters, and gaze points are drawn, color-coded for time (darker are newer)\n",
      "\n",
      "The selected piece (if one exists in the list) has a box around it"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 6: Look at specific episodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infos['episodes'];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "episodeno = 172\n",
      "episode_start = int(infos['episodes']['start_time'].ix[episodeno])\n",
      "episode_end = int(infos['episodes']['end_time'].ix[episodeno])\n",
      "gazeslice = gazegood.ix[episode_start:episode_end]\n",
      "boardslice = boards.ix[episode_start:episode_end]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There would be more than one board during the episode (the initial one and the one after the selection)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boardslice"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can select the last one. e.g."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "boardslice.iloc[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And finally, plot the board + gaze"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_screen(boardslice.iloc[-1], gazeslice)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try plotting some episodes:\n",
      "\n",
      "You need to simply change the episode number 2-3 cells above and rerun the commands to generate the plot"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "STEP 7: Save a plot and upload it to STUDIP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use function plot_screen. Hit SHIFT+TAB inside the parenthesis (twice) to see how you can save to a file\n",
      "\n",
      "Remember to keep this plot for your portfolio\n",
      "\n",
      "Once you have saved the plot to a file, uploaded to StudIP named as follows: \n",
      "\n",
      "FirstNameLastNameScreenPlot.png (or any other valid image format extension)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OPTIONAL CODING TASKS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Create a function that takes as input the episode number and plots the board configuration and gaze points (basically step 6)\n",
      "\n",
      "* Create a function that takes as input a list of tiles and finds out which tile (if any) is selected. Return this tile object or None if no tile is selected. You may assume that only one tile can be selected in the list\n",
      "\n",
      "* Create a simple object type (like we did with the *tile* object). The object would be greated out of something, e.g. a string, or two numbers and create some properties out of it. For example, a *square* object could be created out of a *side length* and also have a property called *area* \n",
      "\n",
      "NOTE on the *split* function for strings:\n",
      "\n",
      "This is a very useful function that allows you to split a string into a list of smaller strings, by specifying a *delimiter*, e.g.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"hello my name is String\".split(\" \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}